module attributes {llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.triple = "x86_64-unknown-linux-gnu", quake.mangled_name_map = {__nvqpp__mlirgen__ghzILm6EE = "_ZN3ghzILm6EEclEv"}} {
  func.func @__nvqpp__mlirgen__ghzILm6EE() attributes {"cudaq-entrypoint", "cudaq-kernel"} {
    %cst = arith.constant -0.78539816339744828 : f64
    %cst_0 = arith.constant -1.5707963267948966 : f64
    %cst_1 = arith.constant 0.78539816339744828 : f64
    %cst_2 = arith.constant -5.000000e+00 : f64
    %cst_3 = arith.constant -3.1415926535897931 : f64
    %cst_4 = arith.constant 1.5707963267948966 : f64
    %cst_5 = arith.constant 3.1415926535897931 : f64
    %cst_6 = arith.constant 0.000000e+00 : f64
    %cst_7 = arith.constant 3.500000e+00 : f64
    %cst_8 = arith.constant 2.340000e+00 : f64
    %0 = quake.alloca !quake.veq<6>
    %1 = quake.extract_ref %0[0] : (!quake.veq<6>) -> !quake.ref
    quake.phased_rx (%cst_4, %cst_4) %1 : (f64, f64, !quake.ref) -> ()
    quake.phased_rx (%cst_5, %cst_6) %1 : (f64, f64, !quake.ref) -> ()
    %2 = quake.extract_ref %0[1] : (!quake.veq<6>) -> !quake.ref
    quake.phased_rx (%cst_4, %cst_4) %2 : (f64, f64, !quake.ref) -> ()
    quake.phased_rx (%cst_5, %cst_6) %2 : (f64, f64, !quake.ref) -> ()
    quake.z [%1] %2 : (!quake.ref, !quake.ref) -> ()
    quake.phased_rx (%cst_4, %cst_4) %2 : (f64, f64, !quake.ref) -> ()
    quake.phased_rx (%cst_5, %cst_6) %2 : (f64, f64, !quake.ref) -> ()
    %3 = quake.extract_ref %0[2] : (!quake.veq<6>) -> !quake.ref
    quake.phased_rx (%cst_4, %cst_4) %3 : (f64, f64, !quake.ref) -> ()
    quake.phased_rx (%cst_5, %cst_6) %3 : (f64, f64, !quake.ref) -> ()
    quake.z [%2] %3 : (!quake.ref, !quake.ref) -> ()
    quake.phased_rx (%cst_4, %cst_4) %3 : (f64, f64, !quake.ref) -> ()
    quake.phased_rx (%cst_5, %cst_6) %3 : (f64, f64, !quake.ref) -> ()
    %4 = quake.extract_ref %0[3] : (!quake.veq<6>) -> !quake.ref
    quake.phased_rx (%cst_4, %cst_4) %4 : (f64, f64, !quake.ref) -> ()
    quake.phased_rx (%cst_5, %cst_6) %4 : (f64, f64, !quake.ref) -> ()
    quake.z [%3] %4 : (!quake.ref, !quake.ref) -> ()
    quake.phased_rx (%cst_4, %cst_4) %4 : (f64, f64, !quake.ref) -> ()
    quake.phased_rx (%cst_5, %cst_6) %4 : (f64, f64, !quake.ref) -> ()
    %5 = quake.extract_ref %0[4] : (!quake.veq<6>) -> !quake.ref
    quake.phased_rx (%cst_4, %cst_4) %5 : (f64, f64, !quake.ref) -> ()
    quake.phased_rx (%cst_5, %cst_6) %5 : (f64, f64, !quake.ref) -> ()
    quake.z [%4] %5 : (!quake.ref, !quake.ref) -> ()
    quake.phased_rx (%cst_4, %cst_4) %5 : (f64, f64, !quake.ref) -> ()
    quake.phased_rx (%cst_5, %cst_6) %5 : (f64, f64, !quake.ref) -> ()
    %6 = quake.extract_ref %0[5] : (!quake.veq<6>) -> !quake.ref
    quake.phased_rx (%cst_4, %cst_4) %6 : (f64, f64, !quake.ref) -> ()
    quake.phased_rx (%cst_5, %cst_6) %6 : (f64, f64, !quake.ref) -> ()
    quake.z [%5] %6 : (!quake.ref, !quake.ref) -> ()
    quake.phased_rx (%cst_4, %cst_4) %6 : (f64, f64, !quake.ref) -> ()
    quake.phased_rx (%cst_5, %cst_6) %6 : (f64, f64, !quake.ref) -> ()
    quake.phased_rx (%cst_4, %cst_4) %1 : (f64, f64, !quake.ref) -> ()
    quake.phased_rx (%cst_5, %cst_6) %1 : (f64, f64, !quake.ref) -> ()
    quake.z [%4] %1 : (!quake.ref, !quake.ref) -> ()
    quake.phased_rx (%cst_4, %cst_4) %1 : (f64, f64, !quake.ref) -> ()
    quake.phased_rx (%cst_5, %cst_6) %1 : (f64, f64, !quake.ref) -> ()
    quake.phased_rx (%cst_4, %cst_4) %4 : (f64, f64, !quake.ref) -> ()
    quake.phased_rx (%cst_5, %cst_6) %4 : (f64, f64, !quake.ref) -> ()
    quake.z [%1] %4 : (!quake.ref, !quake.ref) -> ()
    quake.phased_rx (%cst_4, %cst_4) %4 : (f64, f64, !quake.ref) -> ()
    quake.phased_rx (%cst_5, %cst_6) %4 : (f64, f64, !quake.ref) -> ()
    quake.phased_rx (%cst_4, %cst_4) %1 : (f64, f64, !quake.ref) -> ()
    quake.phased_rx (%cst_5, %cst_6) %1 : (f64, f64, !quake.ref) -> ()
    quake.z [%4] %1 : (!quake.ref, !quake.ref) -> ()
    quake.phased_rx (%cst_4, %cst_4) %1 : (f64, f64, !quake.ref) -> ()
    quake.phased_rx (%cst_5, %cst_6) %1 : (f64, f64, !quake.ref) -> ()
    quake.phased_rx (%cst_8, %cst_6) %1 : (f64, f64, !quake.ref) -> ()
    quake.phased_rx (%cst_7, %cst_4) %2 : (f64, f64, !quake.ref) -> ()
    quake.phased_rx (%cst_4, %cst_6) %3 : (f64, f64, !quake.ref) -> ()
    quake.phased_rx (%cst_2, %cst_4) %3 : (f64, f64, !quake.ref) -> ()
    quake.phased_rx (%cst_0, %cst_6) %3 : (f64, f64, !quake.ref) -> ()
    quake.phased_rx (%cst_4, %cst_4) %4 : (f64, f64, !quake.ref) -> ()
    quake.phased_rx (%cst_5, %cst_6) %4 : (f64, f64, !quake.ref) -> ()
    quake.phased_rx (%cst_4, %cst_4) %4 : (f64, f64, !quake.ref) -> ()
    quake.phased_rx (%cst_5, %cst_6) %4 : (f64, f64, !quake.ref) -> ()
    quake.z [%2] %4 : (!quake.ref, !quake.ref) -> ()
    quake.phased_rx (%cst_4, %cst_4) %4 : (f64, f64, !quake.ref) -> ()
    quake.phased_rx (%cst_5, %cst_6) %4 : (f64, f64, !quake.ref) -> ()
    quake.phased_rx (%cst_4, %cst_6) %4 : (f64, f64, !quake.ref) -> ()
    quake.phased_rx (%cst_1, %cst_4) %4 : (f64, f64, !quake.ref) -> ()
    quake.phased_rx (%cst_0, %cst_6) %4 : (f64, f64, !quake.ref) -> ()
    quake.phased_rx (%cst_4, %cst_4) %4 : (f64, f64, !quake.ref) -> ()
    quake.phased_rx (%cst_5, %cst_6) %4 : (f64, f64, !quake.ref) -> ()
    quake.z [%1] %4 : (!quake.ref, !quake.ref) -> ()
    quake.phased_rx (%cst_4, %cst_4) %4 : (f64, f64, !quake.ref) -> ()
    quake.phased_rx (%cst_5, %cst_6) %4 : (f64, f64, !quake.ref) -> ()
    quake.phased_rx (%cst_4, %cst_6) %4 : (f64, f64, !quake.ref) -> ()
    quake.phased_rx (%cst, %cst_4) %4 : (f64, f64, !quake.ref) -> ()
    quake.phased_rx (%cst_0, %cst_6) %4 : (f64, f64, !quake.ref) -> ()
    quake.phased_rx (%cst_4, %cst_4) %4 : (f64, f64, !quake.ref) -> ()
    quake.phased_rx (%cst_5, %cst_6) %4 : (f64, f64, !quake.ref) -> ()
    quake.z [%2] %4 : (!quake.ref, !quake.ref) -> ()
    quake.phased_rx (%cst_4, %cst_4) %4 : (f64, f64, !quake.ref) -> ()
    quake.phased_rx (%cst_5, %cst_6) %4 : (f64, f64, !quake.ref) -> ()
    quake.phased_rx (%cst_4, %cst_6) %4 : (f64, f64, !quake.ref) -> ()
    quake.phased_rx (%cst_1, %cst_4) %4 : (f64, f64, !quake.ref) -> ()
    quake.phased_rx (%cst_0, %cst_6) %4 : (f64, f64, !quake.ref) -> ()
    quake.phased_rx (%cst_4, %cst_4) %4 : (f64, f64, !quake.ref) -> ()
    quake.phased_rx (%cst_5, %cst_6) %4 : (f64, f64, !quake.ref) -> ()
    quake.z [%1] %4 : (!quake.ref, !quake.ref) -> ()
    quake.phased_rx (%cst_4, %cst_4) %4 : (f64, f64, !quake.ref) -> ()
    quake.phased_rx (%cst_5, %cst_6) %4 : (f64, f64, !quake.ref) -> ()
    quake.phased_rx (%cst_4, %cst_6) %4 : (f64, f64, !quake.ref) -> ()
    quake.phased_rx (%cst, %cst_4) %4 : (f64, f64, !quake.ref) -> ()
    quake.phased_rx (%cst_0, %cst_6) %4 : (f64, f64, !quake.ref) -> ()
    quake.phased_rx (%cst_4, %cst_4) %2 : (f64, f64, !quake.ref) -> ()
    quake.phased_rx (%cst_5, %cst_6) %2 : (f64, f64, !quake.ref) -> ()
    quake.z [%1] %2 : (!quake.ref, !quake.ref) -> ()
    quake.phased_rx (%cst_4, %cst_4) %2 : (f64, f64, !quake.ref) -> ()
    quake.phased_rx (%cst_5, %cst_6) %2 : (f64, f64, !quake.ref) -> ()
    quake.phased_rx (%cst_4, %cst_6) %2 : (f64, f64, !quake.ref) -> ()
    quake.phased_rx (%cst_1, %cst_4) %2 : (f64, f64, !quake.ref) -> ()
    quake.phased_rx (%cst_0, %cst_6) %2 : (f64, f64, !quake.ref) -> ()
    quake.phased_rx (%cst_4, %cst_4) %2 : (f64, f64, !quake.ref) -> ()
    quake.phased_rx (%cst_5, %cst_6) %2 : (f64, f64, !quake.ref) -> ()
    quake.z [%1] %2 : (!quake.ref, !quake.ref) -> ()
    quake.phased_rx (%cst_4, %cst_4) %2 : (f64, f64, !quake.ref) -> ()
    quake.phased_rx (%cst_5, %cst_6) %2 : (f64, f64, !quake.ref) -> ()
    quake.phased_rx (%cst_4, %cst_6) %2 : (f64, f64, !quake.ref) -> ()
    quake.phased_rx (%cst, %cst_4) %2 : (f64, f64, !quake.ref) -> ()
    quake.phased_rx (%cst_0, %cst_6) %2 : (f64, f64, !quake.ref) -> ()
    quake.phased_rx (%cst_4, %cst_6) %1 : (f64, f64, !quake.ref) -> ()
    quake.phased_rx (%cst, %cst_4) %1 : (f64, f64, !quake.ref) -> ()
    quake.phased_rx (%cst_0, %cst_6) %1 : (f64, f64, !quake.ref) -> ()
    quake.phased_rx (%cst_4, %cst_4) %4 : (f64, f64, !quake.ref) -> ()
    quake.phased_rx (%cst_5, %cst_6) %4 : (f64, f64, !quake.ref) -> ()
    quake.phased_rx (%cst_5, %cst_6) %4 : (f64, f64, !quake.ref) -> ()
    quake.phased_rx (%cst_5, %cst_0) %5 : (f64, f64, !quake.ref) -> ()
    quake.phased_rx (%cst_4, %cst_6) %6 : (f64, f64, !quake.ref) -> ()
    quake.phased_rx (%cst_3, %cst_4) %6 : (f64, f64, !quake.ref) -> ()
    quake.phased_rx (%cst_0, %cst_6) %6 : (f64, f64, !quake.ref) -> ()
    quake.phased_rx (%cst_4, %cst_6) %1 : (f64, f64, !quake.ref) -> ()
    quake.phased_rx (%cst_0, %cst_4) %1 : (f64, f64, !quake.ref) -> ()
    quake.phased_rx (%cst_0, %cst_6) %1 : (f64, f64, !quake.ref) -> ()
    quake.phased_rx (%cst_4, %cst_6) %2 : (f64, f64, !quake.ref) -> ()
    quake.phased_rx (%cst, %cst_4) %2 : (f64, f64, !quake.ref) -> ()
    quake.phased_rx (%cst_0, %cst_6) %2 : (f64, f64, !quake.ref) -> ()
    %measOut = quake.mz %0 : (!quake.veq<6>) -> !cc.stdvec<!quake.measure>
    return
  }
  func.func @_ZN3ghzILm6EEclEv(%arg0: !cc.ptr<i8>) {
    return
  }
}
